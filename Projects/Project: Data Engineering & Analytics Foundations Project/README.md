# Data Engineering & Analytics Foundations Project

## Overview
This project documents a step‑by‑step introduction to analytics engineering and data engineering concepts using the Superstore dataset. The workflow mirrors real enterprise practices, including staging, metric extraction, dimensional analysis, and structured documentation.

The goal is to build a repeatable, professional analytics engineering process while developing SQL, analytical reasoning, and data modeling intuition.

---

## Objectives
- Establish a clean, enterprise‑grade SQL workflow.
- Build a structured notes system for analysis.
- Extract core business metrics from a staging table.
- Begin dimensional analysis (category, region, segment).
- Develop habits aligned with analytics engineering best practices.

---

## Dataset
**Source:** `staging.superstore`  
A standard retail dataset containing orders, customers, products, and regional information.

---

## Completed Work (as of 2026‑02‑11)
- Created a dedicated notes file (`project_notes.sql`) in DBeaver.
- Defined a simple, scalable notes structure using headers.
- Extracted core business metrics:
  - Total Sales
  - Total Profit
  - Total Quantity
  - Total Orders
  - Total Customers
  - Avg Discount
  - Avg Profit Margin
- Clarified workflow roles:
  - AI assistant proposes next steps and SQL.
  - Human analyst validates and executes.
- Identified the next phase: dimensional breakdown.

---

## Next Steps
- Sales by Category
- Profit by Category
- Sales by Region
- Profit by Region
- Sales by Segment
- Profit by Segment
- Begin building a modeling mindset (facts, dimensions, grain)

---

## Repository Structure
